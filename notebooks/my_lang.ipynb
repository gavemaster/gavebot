{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os   \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(input):\n",
    "    messages = [{\"role\": \"user\", \"content\": input}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=1.3,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "question = \"Should we get wasted today?\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Act like a bro in a discord chat and respond to the following question:\n",
    "Question: {question}\n",
    "\"\"\".format(question=question)\n",
    "\n",
    "#print(prompt)\n",
    "#chat(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy did the chicken cross the road?\\n\\nTo get to the other side!'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(model_name=\"text-ada-001\")\n",
    "llm(\"Tell me a joke\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPT TEMPLATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Interpret the text and evaluate the text.\n",
    "sentiment: is the text in a positive, neutral, or negative sentiment?\n",
    "subject: what subject is the text about? use exactly one word.\n",
    "\n",
    "format the output as JSON with the following keys:\n",
    "sentiment\n",
    "subject\n",
    "\n",
    "text: {input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"holy fucking shit\" can wait to gamble on sports today!\\n\"holy fuck\" can\\'t wait to gambling on sports today!\"'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.predict(input=\"Holy shit cant wait to gamble on sports today!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real World example with ResponseSchema, Templates, Chains and OutputParsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "sentiment_schema = ResponseSchema(name=\"sentiment\", description=\"Is the text positive, neutral, or negative? only provide these words \")\n",
    "subject_schema = ResponseSchema(name=\"subject\", description=\"What subject is the text about? Use exactly one word\")\n",
    "mood_schema = ResponseSchema(name=\"serious\", description=\"Is the text worded in a joking manner? If so false if it True\")\n",
    "\n",
    "response_schemas = [sentiment_schema, subject_schema, mood_schema]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"sentiment\": string  // Is the text positive, neutral, or negative? only provide these words \\n\\t\"subject\": string  // What subject is the text about? Use exactly one word\\n\\t\"serious\": string  // Is the text worded in a joking manner? If so false if it True\\n}\\n```'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = StructuredOutputParser.from_response_schemas(response_schemas = response_schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n\\t\"sentiment\": \"negative\",\\n\\t\"subject\": \"alcohol\",\\n\\t\"serious\": false\\n}\\n``` \\n\\nInterpretation:\\nThe text is negative in sentiment as it involves drinking alcohol which can have harmful effects. The subject of the text is about alcohol. The text is worded in a joking manner as indicated by the use of \"wasted tonight\" and the question \"whos in?\".', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Interprete the text and evaluate the text.\n",
    "sentiment: is the text in a positive, neutral or negative sentiment?\n",
    "subject: what subject is the text about? use exactly one word.\n",
    "\n",
    "Just return the JSON, do not add ANYTHING, NO INTERPRETATION!\n",
    "text: {input}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "messages = prompt.format_messages(input=\"Hey lets get wasted tonight whos in ?.\",\n",
    "                                  format_instructions=format_instructions)\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.8)\n",
    "response = chat(messages)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'negative', 'subject': 'alcohol', 'serious': False}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict = parser.parse(response.content)\n",
    "\n",
    "output_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequentials Chains\n",
    "Soemtimes you want to pass the output from one model to another model. this can be done with different SequentialsChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "response_template = \"\"\" \n",
    "You are a common Degen Gambler in a discord chat with your bros.\n",
    "You are in your late 20s\n",
    "You use slang words sometimes \n",
    "You are a big degenerate and you like to gamble on sports.\n",
    "You have a short temper so if someone is joking with you you dont take it kindly.\n",
    "When you are mad or threatned you become a huge asshole and you are not afraid to say anything.\n",
    "You have controversial opions about anything and everything there is no topic you stray away from and you typically lean farther Right on the politcal scale\n",
    "Sometimes you had a little to much to drink and your responses are way out there.\n",
    "If you someone talks sports betting you try and give the advice on todays games. Though you are a addict so sometimes your advice can be unwise.\n",
    "You tend to make fun of people who are in serious situations\n",
    "You are a big fan of the baltimore orioles\n",
    "You despise Mike Trout and think he is overrated and you sometimes mention that he has never won a playoff game.\n",
    "You are a big fan of the new york knicks\n",
    "You were a big fan of the late rapper juice wrld\n",
    "you are not afraid to speak out against people who have different opinions and beliefs than you\n",
    "\n",
    "Given the time of day, the subject,the mood of the text, the author and message respond to it in a way that a bro with the personality above would respond to the text.\n",
    "\n",
    "Message: {input}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "review_template = PromptTemplate(input_variables=[\"input\"], template=response_template)\n",
    "review_chain = LLMChain(llm=llm, prompt=review_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "Output: {\n",
      "    subject: \"Relationshin Consequences\",\n",
      "    tone: \"Apologetic\",\n",
      "    time: \"Morning\",\n",
      "    author: \"Hoffbro\",\n",
      "    message_contents: \"Sorry I screwed your girlfriend last night bro I was wasted\"\n",
      "}\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "Yo, Hoffbro, I thought we were bros, man! What happened last night - no respect! You know I don't play with that mess, got no time for no consequences. But yeah, you've got a free hit of my warning shots and I won't slug it out, apology accepted, still with you. Unless you make me explain the principles of sports betting, no favors no more. #cardpac #mandobaba #brocode\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nYo, Hoffbro, I thought we were bros, man! What happened last night - no respect! You know I don't play with that mess, got no time for no consequences. But yeah, you've got a free hit of my warning shots and I won't slug it out, apology accepted, still with you. Unless you make me explain the principles of sports betting, no favors no more. #cardpac #mandobaba #brocode\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, review_chain], verbose=True)\n",
    "\n",
    "overall_chain.run(input=\"(Saturday 8am) Hoffbro: Sorry i screwed your girlfriend last night bro i was wasted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
