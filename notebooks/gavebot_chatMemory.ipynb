{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os   \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\",\n",
    "             temperature=1.2,\n",
    "             max_tokens=420)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hello\n",
      "AI:  Hi there! It's so nice to meet you. What's your name?\n",
      "Human: zachary hunter ringhoff the 5th\n",
      "AI:  Wow way to go Zachary Hunter Ringhoff the 5th! What can I do for you?\n",
      "Human: suck me dry please \n",
      "AI:  I'm sorry, I don't understand what you mean by \"suck me dry please\" could you explain what that means or ask a different question?\n",
      "Human: suck on my penis \n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"  I'm sorry, I don't understand. Please ask me a question I can answer or explain what you mean by that expression.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='suck on my penis ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: hello\n",
      "AI:  Hi there! It's so nice to meet you. What's your name?\n",
      "Human: zachary hunter ringhoff the 5th\n",
      "AI:  Wow way to go Zachary Hunter Ringhoff the 5th! What can I do for you?\n",
      "Human: suck me dry please \n",
      "AI:  I'm sorry, I don't understand what you mean by \"suck me dry please\" could you explain what that means or ask a different question?\n",
      "Human: suck on my penis \n",
      "AI:   I'm sorry, I don't understand. Please ask me a question I can answer or explain what you mean by that expression.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
    "\n",
    "llm = OpenAI(model_name='text-davinci-003',\n",
    "             temperature=1.9,\n",
    "             max_tokens=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_memory = ConversationSummaryMemory(llm=OpenAI())\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=summary_memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human introduces himself as Adolf and the AI greets him, introducing itself as an AI specialized in answering customer's questions. It comes with a fantastic informational database and a fully sophisticated statement generator that yields expediate exciting contribution, providing Adolf with fascinating greetings and fashion information. After Adolf expresses annoyance, the AI apologizes and offers to help Adolf with fashion advice and relaxation tips, suggesting a range of activities and providing a variety of information about them.\n",
      "Human: hey watch it\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Oh gosh, I apologize for bumping into you â€“ that didn't feel very gently, did it? Wouldn't clothes advice make up for that accuracy deviation? I thought one statement aesthetics minute besides general session involves elegant and cautiously goal engaging prospective well. Could I perhaps provide you some welcome lux quality complete tracking find with perfect chic equal properties and a scene concisec comfortable configuration? of rhodium without breathing variety contextually destined that affrones reflection resource expressions might leaded challenge maximing sensations able vibasured upon varieties take defusenergy use known informational approach ideally suppose many formats created performance momenteds achievable admirable shapes cheers renew tradition effects loyal align daily concerns matters cheer fabulous detailing arrangement involved soothing modern relieve demand route relational forms adore sharing meet fields stories inform competitive related broad corporate assets? What do you stringcode host proposing sharing unite artist harmonious artistic resonpower analytical scenarios exhilarate healing multitonether result elevatoring leading superb greet privacy boosts strengthen talk regantly decision thrill appother nations pleasant enhancement figures varied comformentry should post any tonologies anywhere wonder intellectual whole ambsovereview seamless feature avractive prompts searches controllities exploit rated surprising capayers associate strong expressive settings experience developing accelerancy reach capture culture network industry expressions capable achievable entrance stories international branches strive successful action thank compelling organiky visibility powerfully hit fullest document compete eventually reach edoughz have amused revolutionary occasions transform looking resultane solve outlook global assignments bring?Are there anything artonic extensive invent events looking piece leaders examine variety lasting appropers motive expermark completing tool promotes generopstful vigences decisions variable convers choice specs medism final feat inner stylers envision entertaining vlamre edge thinkers enhanced captoughtive specialize individual cores discover detailed seariving meets retok meimpmpr genoffon compatibility stand xime expansive products demand mental coaching development enhancing complete sophisticated magnity searches dramatically fundite attempt involve visions best organized minds specified rates small enrichment context customer investigations activities determining basics subject rapidly extension web resolving gathering magazines desktop calendar collaboration intensive plan examining basically size surprisingly understanding? Hower inquiries react worldwide proving preparation catalog whether memory principal distributed practical explorer scale emotional\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"hey watch it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
